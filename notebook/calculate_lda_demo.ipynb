{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9ba500a-e1de-4114-910f-ac5dc90fe720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 30 11:35:30 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 516.94       Driver Version: 516.94       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| 45%   32C    P8    N/A /  75W |   1221MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1132    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      1888    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      2352    C+G   ...e\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      5980    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A      6688    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A      7348    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A      7896    C+G   ...3d8bbwe\\CalculatorApp.exe    N/A      |\n",
      "|    0   N/A  N/A      9992    C+G   ...8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
      "|    0   N/A  N/A     10504    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     10956    C+G   ...root\\Office16\\WINWORD.EXE    N/A      |\n",
      "|    0   N/A  N/A     11184    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     12160    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A     13504    C+G   ...774.57\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     13552    C+G   ...8wekyb3d8bbwe\\GameBar.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1c9ee68-7f23-4175-b317-6daaf6b79a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libary\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory, StopWordRemover, ArrayDictionary\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import gensim\n",
    "from gensim import models\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models import Phrases, CoherenceModel\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import Label\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a1d61a9-cb93-4151-a0cb-1b797388c69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pandas DataFrame\n",
    "df = pd.DataFrame([ \n",
    "                   # ['Cukup bagus dan Tempatnya tertata rapi Karena dibuatkan Tempat untuk berfoto'],\n",
    "                   ['lokasi curug indah sejuk baik kondisi jalan sempit becek hujan'],\n",
    "                   ['saran hujan jalan curug licin becek ojek antar curug'],\n",
    "                   ['tempat bagus akses curug jalan tanah hujan anjur'],\n",
    "                   # ['Overall is good, cuma Lokasinya jauh.. Fasilitasnya masih harus dilengkapi lagi..'],\n",
    "                   # ['Jalan menuju kesini sekarang sudah manusiawi. Jangan ragu buat bawa motor atau mobil'],\n",
    "                   # ['Sangat bagus sekali alam air terjunnya, cuma sayang jarak dari tempat saya sangat jauh sekali kurang lebih 185 km'],\n",
    "                   # ['Capenya perjalanan terbayarkan dg keindahan dan ke eksotisannya'],\n",
    "                   # ['Sangat luar biasa ini tempat, Asri, sejuk dan wah dah. Bersama istri tercinta jalan2 ke sini.'],\n",
    "                   # ['Tempatnya bagus, alam banget, buat camping juga cocok ada sungainya'],\n",
    "                   # ['Perjuangan banget pokonya buat smpe ke curugnya, tp semua terbayarkan ðŸ˜Š â€¦'],\n",
    "                   # ['curug nya banyak bisa ambil beberapa foto deh mantap'],\n",
    "                   # ['Tempatnya bagus, cuman kurang petunjuk lokasi wisatanya'],\n",
    "                  ], columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d54b983-9fa7-4e19-9189-8bcd92577e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['text'].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e45a1149-88a6-46e7-bcda-6cdd74f8847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62bae418-1815-47f7-8773-a524bdea8e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Corpus\n",
    "id2word = corpora.Dictionary(texts)\n",
    "# id2word.filter_extremes(no_below=5, no_above=0.2)\n",
    "\n",
    "# texts = df['tokens']\n",
    "# corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a572e7f1-12d2-4ee7-b236-01c94ae7dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoW Corpus\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "148cde40-904b-480c-9912-1373204f68c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Corpus\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e4f06bf-11ef-4684-b6c6-3937e4f77cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.40369167389095173),\n",
       " (1, 0.1489905855640844),\n",
       " (4, 0.40369167389095173),\n",
       " (6, 0.40369167389095173),\n",
       " (7, 0.40369167389095173),\n",
       " (8, 0.40369167389095173),\n",
       " (9, 0.40369167389095173)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tfidf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3687270-3a3b-4330-9ec9-f995e8067249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1),\n",
       "  (1, 1),\n",
       "  (2, 1),\n",
       "  (3, 1),\n",
       "  (4, 1),\n",
       "  (5, 1),\n",
       "  (6, 1),\n",
       "  (7, 1),\n",
       "  (8, 1),\n",
       "  (9, 1)],\n",
       " [(1, 1), (2, 2), (3, 1), (5, 1), (10, 1), (11, 1), (12, 1), (13, 1)],\n",
       " [(2, 1), (3, 1), (5, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1)]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a2878be-8ae4-4481-8619-6e6a7942307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_values = 0\n",
    "\n",
    "model = LdaModel( #LdaModel\n",
    "            corpus=corpus, id2word=id2word, num_topics=2, random_state=42, iterations=1, alpha=1, eta=1\n",
    "            # chunksize=2000, passes=1, update_every=1, alpha='symmetric', eta=None, \n",
    "            # decay=0.5, offset=1.0, eval_every=10, gamma_threshold=0.001\n",
    "            )\n",
    "\n",
    "coherence_model = CoherenceModel(\n",
    "                    model=model, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "coherence_values = coherence_model.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee262021-74e3-44e9-88c7-6431df781753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2799258811857321\n"
     ]
    }
   ],
   "source": [
    "print(coherence_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82c4fce5-efa3-4885-9c57-18412b76440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.show_topics(num_topics=2, formatted=False)\n",
    "topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "879c89f8-a6d2-4c4c-9e4f-caa49fa12103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: ['curug', 'hujan', 'jalan', 'becek', 'ojek', 'saran', 'licin', 'baik', 'indah', 'tanah']\n",
      "Topic 1: ['curug', 'jalan', 'hujan', 'becek', 'sempit', 'bagus', 'kondisi', 'akses', 'antar', 'anjur']\n"
     ]
    }
   ],
   "source": [
    "# Below Code Prints Topics and Words\n",
    "for topic, words in topics_words:\n",
    "    print(f'Topic {topic}: {words}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37b66b17-74cf-4efa-b448-396c3dc45498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0, Word: 0.098*\"curug\" + 0.080*\"hujan\" + 0.076*\"jalan\" + 0.059*\"becek\" + 0.049*\"ojek\" + 0.048*\"saran\" + 0.047*\"licin\" + 0.047*\"baik\" + 0.047*\"indah\" + 0.046*\"tanah\"\n",
      "Topic: 1, Word: 0.087*\"curug\" + 0.078*\"jalan\" + 0.073*\"hujan\" + 0.064*\"becek\" + 0.049*\"sempit\" + 0.048*\"bagus\" + 0.048*\"kondisi\" + 0.048*\"akses\" + 0.048*\"antar\" + 0.048*\"anjur\"\n"
     ]
    }
   ],
   "source": [
    "# Below Code Prints Topics and Words with probability\n",
    "for idx, topic in model.print_topics(-1):\n",
    "    print(f'Topic: {idx}, Word: {topic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fde3ba1-5753-42db-8a0b-04a71d9ef8da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eff43a4-67d4-4a3b-910b-6ee244d57e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = list(df['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394befe8-64a6-4a1c-9fd8-63d046250e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "D_topics = []\n",
    "for i in range(len(D)):\n",
    "    d_topic = []\n",
    "    for j in range(len(D[i])):\n",
    "        d_topic.append(randint(1,2))\n",
    "    D_topics.append(d_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15ef4e8-6de4-4737-848a-372f039f560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f38cebf-b505-4f61-87ea-88230b0e2a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc807784-1c48-4415-b7f6-2e77ed6ffb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_all = []\n",
    "for i in range(len(D)):\n",
    "    for j in range(len(D[i])):\n",
    "        w_all.append(D[i][j])\n",
    "\n",
    "w_all = list(dict.fromkeys(w_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd036a11-eab9-48ce-8ccf-55cb064dc326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pandas DataFrame\n",
    "prob_word_each_topic = pd.DataFrame([[word] for word in w_all], columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26a85f6-1e2a-402d-943e-4a18d032dcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_all = []\n",
    "for word_idx in range(len(prob_word_each_topic)):\n",
    "    topic_1 = 0\n",
    "    topic_2 = 0\n",
    "    # topic_3 = 0\n",
    "    for doc in range(len(D)):\n",
    "        for word_in_doc in range(len(D[doc])):\n",
    "            if prob_word_each_topic['text'][word_idx] == D[doc][word_in_doc]:\n",
    "                if D_topics[doc][word_in_doc] == 1:\n",
    "                    topic_1 += 1\n",
    "                elif D_topics[doc][word_in_doc] == 2:\n",
    "                    topic_2 += 1\n",
    "                # elif D_topics[doc][word_in_doc] == 3:\n",
    "                #     topic_3 += 1\n",
    "    topic_all.append([topic_1, topic_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfa8557-4595-4bb4-a6c4-f0794921ffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob_word_each_topic_2 = prob_word_each_topic.append(topic_all, columns=['topic_1', 'topic_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e00285-8046-4891-b981-a63db18e4f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30712ac3-52f9-42a4-aeed-1ba66a2ce0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_1_sum = 0\n",
    "topic_2_sum = 0\n",
    "for value_topic in topic_all:\n",
    "    topic_1_sum += value_topic[0]\n",
    "    topic_2_sum += value_topic[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f47d8ed-d360-4215-9aab-3b689e4e85be",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_1_sum, topic_2_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a776178a-370a-457c-a43d-2f28aca78e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "array1 = np.array([[word] for word in w_all])\n",
    "array2 = np.array(topic_all)\n",
    "joined = np.concatenate((array1, array2), axis=1)\n",
    "\n",
    "prob_word_each_topic = pd.DataFrame(joined, columns=['text', 'topic_1', 'topic_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78a5e34-a1a5-4fd3-b205-6002d6d4d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_word_each_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40bdf86-e08b-4f25-a518-eb59f094fb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_topic_each_word = []\n",
    "for d in D_topics:\n",
    "    topic_1 = 0\n",
    "    topic_2 = 0\n",
    "    for topic_value_idx in range(len(d)):\n",
    "        if d[topic_value_idx] == 1:\n",
    "            topic_1 += 1\n",
    "        elif d[topic_value_idx] == 2:\n",
    "            topic_2 += 1\n",
    "    prob_topic_each_word.append([topic_1, topic_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85be72af-920e-4e9f-9ab4-0d52627efe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_topic_each_word = pd.DataFrame(prob_topic_each_word, columns=['topic_1', 'topic_2'])\n",
    "prob_topic_each_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bca6296-8090-4252-991d-dfab3913e444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b647cbc0-d185-4737-84a5-307d39e24ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdocs = [\n",
    "    'akses mudah tempat indah pisan seperti curug',\n",
    "    'ada fasilitas outbound paintball pegawai cukup ramah',\n",
    "    'tempat enak buat hiking harga makanan cukup terjangkau',\n",
    "    'tempat bagus cocok buat healing keluarga banyak spot foto',\n",
    "    'bagus untuk camping dan melihat sunrise tarif relatif murah',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a92a15-ff58-4c23-bf83-cd190f7fad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [doc.split(' ') for doc in rawdocs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b00f31-8bb9-43c4-a80d-de90ac333a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique words\n",
    "from itertools import chain\n",
    "\n",
    "vocabs = list(dict.fromkeys(chain.from_iterable(docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092cc332-a875-4f89-9855-6bfd4ff19953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace words in documents with wordIDs\n",
    "docs_idx = []\n",
    "for i in range(len(docs)):\n",
    "    doc_idx = []\n",
    "    for j in range(len(docs[i])):\n",
    "        for vocab_idx in range(len(vocabs)):\n",
    "            if vocabs[vocab_idx] == docs[i][j]:\n",
    "                doc_idx.append(vocab_idx)\n",
    "    docs_idx.append(doc_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adbbdfe-b2f2-4dfb-adf7-9ac13921dd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f17780-7431-492c-ba9d-766797791807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bd772b6-3dc5-4242-94ce-2221f39b8dc6",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3621935-a13d-4568-be55-37ee490a7fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9401adb7-6790-4889-b8e3-cb00b5bd643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'lokasi curug indah sejuk baik kondisi jalan sempit becek hujan',\n",
    "    'saran hujan jalan curug licin becek ojek antar curug',\n",
    "    'tempat bagus akses curug jalan tanah hujan anjur',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c91fc410-bb70-49fd-825a-175036eda4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in the corpus: 19\n",
      "The words in the corpus: \n",
      " {'antar', 'akses', 'sejuk', 'curug', 'bagus', 'saran', 'ojek', 'anjur', 'hujan', 'sempit', 'tanah', 'indah', 'jalan', 'licin', 'tempat', 'becek', 'lokasi', 'kondisi', 'baik'}\n"
     ]
    }
   ],
   "source": [
    "words_set = set()\n",
    "\n",
    "for doc in  corpus:\n",
    "    words = doc.split(' ')\n",
    "    words_set = words_set.union(set(words))\n",
    "    \n",
    "print('Number of words in the corpus:',len(words_set))\n",
    "print('The words in the corpus: \\n', words_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "902b8589-4910-40d2-b74e-2f717d33793a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antar</th>\n",
       "      <th>akses</th>\n",
       "      <th>sejuk</th>\n",
       "      <th>curug</th>\n",
       "      <th>bagus</th>\n",
       "      <th>saran</th>\n",
       "      <th>ojek</th>\n",
       "      <th>anjur</th>\n",
       "      <th>hujan</th>\n",
       "      <th>sempit</th>\n",
       "      <th>tanah</th>\n",
       "      <th>indah</th>\n",
       "      <th>jalan</th>\n",
       "      <th>licin</th>\n",
       "      <th>tempat</th>\n",
       "      <th>becek</th>\n",
       "      <th>lokasi</th>\n",
       "      <th>kondisi</th>\n",
       "      <th>baik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      antar  akses  sejuk     curug  bagus     saran      ojek  anjur  \\\n",
       "0  0.000000  0.000    0.1  0.100000  0.000  0.000000  0.000000  0.000   \n",
       "1  0.111111  0.000    0.0  0.222222  0.000  0.111111  0.111111  0.000   \n",
       "2  0.000000  0.125    0.0  0.125000  0.125  0.000000  0.000000  0.125   \n",
       "\n",
       "      hujan  sempit  tanah  indah     jalan     licin  tempat     becek  \\\n",
       "0  0.100000     0.1  0.000    0.1  0.100000  0.000000   0.000  0.100000   \n",
       "1  0.111111     0.0  0.000    0.0  0.111111  0.111111   0.000  0.111111   \n",
       "2  0.125000     0.0  0.125    0.0  0.125000  0.000000   0.125  0.000000   \n",
       "\n",
       "   lokasi  kondisi  baik  \n",
       "0     0.1      0.1   0.1  \n",
       "1     0.0      0.0   0.0  \n",
       "2     0.0      0.0   0.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_docs = len(corpus)         #Â·Number of documents in the corpus\n",
    "n_words_set = len(words_set) #Â·Number of unique words in the \n",
    "\n",
    "df_tf = pd.DataFrame(np.zeros((n_docs, n_words_set)), columns=words_set)\n",
    "# print(df_tf)\n",
    "# Compute Term Frequency (TF)\n",
    "for i in range(n_docs):\n",
    "    words = corpus[i].split(' ') # Words in the document\n",
    "    for w in words:\n",
    "        df_tf[w][i] = df_tf[w][i] + (1 / len(words))\n",
    "        \n",
    "df_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0350d4e5-799c-4516-b67b-4adc80571458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF of: \n",
      "        kondisi: 0.47712125471966244\n",
      "           baik: 0.47712125471966244\n",
      "          jalan:        0.0\n",
      "          becek: 0.17609125905568124\n",
      "         sempit: 0.47712125471966244\n",
      "          anjur: 0.47712125471966244\n",
      "          akses: 0.47712125471966244\n",
      "          licin: 0.47712125471966244\n",
      "          curug:        0.0\n",
      "          antar: 0.47712125471966244\n",
      "           ojek: 0.47712125471966244\n",
      "          indah: 0.47712125471966244\n",
      "          sejuk: 0.47712125471966244\n",
      "         tempat: 0.47712125471966244\n",
      "          hujan:        0.0\n",
      "         lokasi: 0.47712125471966244\n",
      "          saran: 0.47712125471966244\n",
      "          tanah: 0.47712125471966244\n",
      "          bagus: 0.47712125471966244\n"
     ]
    }
   ],
   "source": [
    "print(\"IDF of: \")\n",
    "\n",
    "idf = {}\n",
    "\n",
    "for w in words_set:\n",
    "    k = 0    # number of documents in the corpus that contain this word\n",
    "    \n",
    "    for i in range(n_docs):\n",
    "        if w in corpus[i].split():\n",
    "            k += 1\n",
    "            \n",
    "    idf[w] =  np.log10(n_docs / k)\n",
    "    \n",
    "    print(f'{w:>15}: {idf[w]:>10}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef53c841-05d8-4a76-aabc-c40f214e9c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kondisi</th>\n",
       "      <th>baik</th>\n",
       "      <th>jalan</th>\n",
       "      <th>becek</th>\n",
       "      <th>sempit</th>\n",
       "      <th>anjur</th>\n",
       "      <th>akses</th>\n",
       "      <th>licin</th>\n",
       "      <th>curug</th>\n",
       "      <th>antar</th>\n",
       "      <th>ojek</th>\n",
       "      <th>indah</th>\n",
       "      <th>sejuk</th>\n",
       "      <th>tempat</th>\n",
       "      <th>hujan</th>\n",
       "      <th>lokasi</th>\n",
       "      <th>saran</th>\n",
       "      <th>tanah</th>\n",
       "      <th>bagus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.047712</td>\n",
       "      <td>0.047712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017609</td>\n",
       "      <td>0.047712</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047712</td>\n",
       "      <td>0.047712</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.053013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053013</td>\n",
       "      <td>0.053013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053013</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05964</td>\n",
       "      <td>0.05964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05964</td>\n",
       "      <td>0.05964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    kondisi      baik  jalan     becek    sempit    anjur    akses     licin  \\\n",
       "0  0.047712  0.047712    0.0  0.017609  0.047712  0.00000  0.00000  0.000000   \n",
       "1  0.000000  0.000000    0.0  0.019566  0.000000  0.00000  0.00000  0.053013   \n",
       "2  0.000000  0.000000    0.0  0.000000  0.000000  0.05964  0.05964  0.000000   \n",
       "\n",
       "   curug     antar      ojek     indah     sejuk   tempat  hujan    lokasi  \\\n",
       "0    0.0  0.000000  0.000000  0.047712  0.047712  0.00000    0.0  0.047712   \n",
       "1    0.0  0.053013  0.053013  0.000000  0.000000  0.00000    0.0  0.000000   \n",
       "2    0.0  0.000000  0.000000  0.000000  0.000000  0.05964    0.0  0.000000   \n",
       "\n",
       "      saran    tanah    bagus  \n",
       "0  0.000000  0.00000  0.00000  \n",
       "1  0.053013  0.00000  0.00000  \n",
       "2  0.000000  0.05964  0.05964  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf_idf = df_tf.copy()\n",
    "\n",
    "for w in words_set:\n",
    "    for i in range(n_docs):\n",
    "        df_tf_idf[w][i] = df_tf[w][i] * idf[w]\n",
    "        \n",
    "df_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b03a1d-2051-4685-8f7d-ac49d9523d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
